{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left</td>\n",
       "      <td>WASHINGTON  —   Jefferson Beauregard Sessions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>left</td>\n",
       "      <td>On Wednesday, the Senate Environment and Publi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>left</td>\n",
       "      <td>Nina Falcone has given up on cash. Whenever an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>left</td>\n",
       "      <td>MOSCOW  —   A gunman stormed a police station ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>left</td>\n",
       "      <td>The great American consumer is very much alive...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            content\n",
       "0  left  WASHINGTON  —   Jefferson Beauregard Sessions ...\n",
       "1  left  On Wednesday, the Senate Environment and Publi...\n",
       "2  left  Nina Falcone has given up on cash. Whenever an...\n",
       "3  left  MOSCOW  —   A gunman stormed a police station ...\n",
       "4  left  The great American consumer is very much alive..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# load dataset prepared in wrangle_news.py\n",
    "news = pd.read_csv('/Users/daniel/Documents/Work/ProDev/Data Science/video_digest/text_classification_all/news.csv', index_col=0)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IF-IDF Logistic regression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in train test (default 0.25 test)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(news['content'],news['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize raw test data\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,2))\n",
    "X_train = vectorizer.fit_transform(X_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train LR classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82073704 0.811875   0.8225     0.82625    0.82363977]\n"
     ]
    }
   ],
   "source": [
    "# Test model accuracy, 5x cross validation\n",
    "x_test = vectorizer.transform(X_test_raw)\n",
    "scores = cross_val_score(classifier, x_test, y_test, cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do predictions\n",
    "predictions = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       left       0.87      0.86      0.87      3989\n",
      "      right       0.86      0.88      0.87      4011\n",
      "\n",
      "avg / total       0.87      0.87      0.87      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# report metrics\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for vectorizer = TfidfVectorizer(ngram_range = (1,3)):\n",
    "\n",
    "Scores\n",
    "[0.81449094 0.80125    0.813125   0.824375   0.8217636 ]\n",
    "\n",
    "Report\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "       left       0.82      0.89      0.85      3989\n",
    "      right       0.88      0.80      0.84      4011\n",
    "\n",
    "avg / total       0.85      0.84      0.84      8000\n",
    "\n",
    "All defaults was 0.86, same with english stopwords. With max_features = 1000 it's .81\n",
    "Best is ngrams 1-2 at .87, all else default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breitbart Coulter transcript\n",
    "with open('transcript_bb_coulter.txt', 'r') as myfile:\n",
    "    text=myfile.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This transcript was classified as politically right, with a probability of 0.7226171835505644']\n",
      "this is you know these Dreams by Masters they are idea for flipping an election to Trump is will take out these 13 Russians will put Facebook ads Annapolis way that will have will be putting our finger on on this election more than the entire media in the United States no match \n"
     ]
    }
   ],
   "source": [
    "# Single prediction\n",
    "text = X_test_raw[20583]\n",
    "exemplar = vectorizer.transform([text]) # example string\n",
    "exemplar_cat = classifier.predict(exemplar) # returns category\n",
    "exemplar_prob = classifier.predict_proba(exemplar) # returns probability\n",
    "\n",
    "if exemplar_prob[0][0] > exemplar_prob[0][1]:\n",
    "    class_prob = exemplar_prob[0][0]\n",
    "else: class_prob = exemplar_prob[0][1]\n",
    "\n",
    "print('This transcript was classified as politically ' + exemplar_cat + ', with a probability of ' + str(class_prob))\n",
    "print(text[1:280])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the' 'on on' 'dominant on']\n"
     ]
    }
   ],
   "source": [
    "# Most important features\n",
    "feature_array = np.array(vectorizer.get_feature_names())\n",
    "tfidf_sorting = np.argsort(exemplar.toarray()).flatten()[::-1]\n",
    "\n",
    "n = 3\n",
    "top_n = feature_array[tfidf_sorting][:n]\n",
    "print(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Load classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save trained LR model\n",
    "import pickle\n",
    "\n",
    "file_Name = \"classifier_pol\"\n",
    "\n",
    "fileObject = open(file_Name,'wb') \n",
    "pickle.dump(classifier,fileObject)   \n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To open the file for reading\n",
    "fileObject = open(file_Name,'rb')\n",
    "classifier_pol_bias = pickle.load(fileObject)  \n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ﬂed', 'keola', 'kentwood', 'kenyatta', 'kenzaburo', 'kenzie', 'kenzo', 'keohane', 'keokuk', 'keoni']\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(vectorizer.idf_)[::-1]\n",
    "features = vectorizer.get_feature_names()\n",
    "top_n = 10\n",
    "top_features = [features[i] for i in indices[:top_n]]\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "features_by_gram = defaultdict(list)\n",
    "for f, w in zip(vectorizer.get_feature_names(), vectorizer.idf_):\n",
    "    features_by_gram[len(f.split(' '))].append((f, w))\n",
    "top_n = 2\n",
    "for gram, features in features_by_gram.items():\n",
    "    top_features = sorted(features, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    top_features = [f[0] for f in top_features]\n",
    "    #print '{}-gram top:'.format(gram), top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
