{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process submitted sample audio clips (\"fucks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusing sample audio files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "\n",
    "sample_list = os.listdir('samples/')\n",
    "\n",
    "comb = silence_chunk\n",
    "for i, sample in enumerate(sample_list):\n",
    "    one = AudioSegment.from_file(\"samples/\" + sample)\n",
    "    comb = comb + silence_chunk + one\n",
    "    \n",
    "comb.export('fucks_all.wav', format = 'wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting audio files on silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "def match_target_amplitude(aChunk, target_dBFS):\n",
    "    ''' Normalize given audio chunk '''\n",
    "    change_in_dBFS = target_dBFS - aChunk.dBFS\n",
    "    return aChunk.apply_gain(change_in_dBFS)\n",
    "\n",
    "song = AudioSegment.from_file(\"misc_audio/fucks_all.wav\")\n",
    "\n",
    "#split track where silence is 200ms+ and get chunks\n",
    "\n",
    "chunks = split_on_silence(song, \n",
    "    # must be silent for at least x ms\n",
    "    min_silence_len=300,\n",
    "\n",
    "    # consider it silent if quieter than threshold dBFS\n",
    "    silence_thresh=-36 \n",
    ")\n",
    "\n",
    "#Process each chunk per requirements\n",
    "for i, chunk in enumerate(chunks):\n",
    "    #Create 0.5 seconds silence chunk\n",
    "    silence_chunk = AudioSegment.silent(duration=100)\n",
    "\n",
    "    #Add  0.5 sec silence to beginning and end of audio chunk\n",
    "    audio_chunk = silence_chunk + chunk + silence_chunk\n",
    "\n",
    "    #Normalize each audio chunk\n",
    "    normalized_chunk = match_target_amplitude(audio_chunk, -20.0)\n",
    "\n",
    "    #Export audio chunk with new bitrate\n",
    "    print(\"exporting fuck{0}.mp3\".format(i) )\n",
    "    normalized_chunk.export(\".//train/fucks_wav/fuck{0}.wav\".format(i), bitrate='192k', format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make non-fuck clips of comparable length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select N random clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# import transcripts to a dataframe\n",
    "meta_train = pd.read_csv('cv_corpus_v1/cv-valid-train.csv')\n",
    "\n",
    "n = 1000\n",
    "randoms = random.sample(range(0, len(meta_train)), n)\n",
    "\n",
    "selection = meta_train.iloc[randoms, [0,1]]\n",
    "selection.sort_index(inplace=True)\n",
    "selection = selection.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop 1s from 1000 mozilla mp3 files & copy over as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "for x in selection.filename:\n",
    "    file_path = str('cv_corpus_v1/' + x)\n",
    "    file_name = x[-17:-4]\n",
    "    clip = AudioSegment.from_file(file_path)\n",
    "    \n",
    "    duration = len(clip)\n",
    "    crop_start = random.sample(range(0, duration - 1000), 1)[0]\n",
    "    crop_end = crop_start + random.sample(range(300, 1000), 1)[0]\n",
    "    \n",
    "    silence_chunk = AudioSegment.silent(duration=100)\n",
    "    cropped_clip = silence_chunk + clip[crop_start : crop_end] + silence_chunk\n",
    "    \n",
    "    cropped_clip.export('train/other_wav/' + str(file_name) + '-cropped.wav', format = 'wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split my test read into 2s clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "test_all = AudioSegment.from_file('misc_audio/fuck_history.wav')\n",
    "len(test_all)\n",
    "\n",
    "start_times = []\n",
    "for i in range(0, 346000, 500):\n",
    "    start_times.append(i)\n",
    "    \n",
    "for i in start_times:\n",
    "    clip = test_all[i:(i+500)]\n",
    "    silence_chunk = AudioSegment.silent(duration=100)\n",
    "    cropped_clip = silence_chunk + clip + silence_chunk\n",
    "    cropped_clip.export('test/test_wav/test_' + str(i) + '.wav', format = 'wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15500.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "62000/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
