{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic classification with Google Natural Language API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "\n",
    "from google.cloud import language\n",
    "import numpy\n",
    "import six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text, verbose=True):\n",
    "    \"\"\"Classify the input text into categories. \"\"\"\n",
    "\n",
    "    language_client = language.LanguageServiceClient()\n",
    "\n",
    "    document = language.types.Document(\n",
    "        content=text,\n",
    "        type=language.enums.Document.Type.PLAIN_TEXT)\n",
    "    response = language_client.classify_text(document)\n",
    "    categories = response.categories\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    for category in categories:\n",
    "        # Turn the categories into a dictionary of the form:\n",
    "        # {category.name: category.confidence}, so that they can\n",
    "        # be treated as a sparse vector.\n",
    "        result[category.name] = category.confidence\n",
    "\n",
    "    if verbose:\n",
    "        print(text)\n",
    "        for category in categories:\n",
    "            print(u'=' * 20)\n",
    "            print(u'{:<16}: {}'.format('category', category.name))\n",
    "            print(u'{:<16}: {}'.format('confidence', category.confidence))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nvLDA70ZvbU_t.txt', 'r') as myfile:\n",
    "    transcript=myfile.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hello there the stroke can you hear me you see there's something very important about don't tell me  no I already sent you a Pikachu a little while back but no Professor I actually have a ditto for you to  that was going to be my next PS well you see the thing is Professor it's not just any did I want to discuss the Pokemon this dytto has transformed itself into  have a look at this video  Pokemon Planet well if that's the case Professor it must be a new Pokemon undiscovered till now there's been numerous sightings of this Pokemon reported over the past few days but it turns out that all of them were just transformed it out that's all we got right now I have seen this text I once read so you've heard of it yes if I'm not mistaken it could be the mythical Pokemon  Helltown found it this is the text the description here matches the end that you sent me you're right but it does make you wonder what kind of Pokemon metal ten eyck be Uno's but I am excited to find out Professor I'll keep Gathering any information I can find and I'll keep going through these texts as well as taking a closer look at that. Sending my way I knew you wouldn't let me down I consider myself very lucky to have you as mine that I know right I'll be in touch  Mountain melt and its name huh that's got a nice ring to it right looks like it's time to do some field work\n",
      "====================\n",
      "category        : /Games\n",
      "confidence      : 0.6800000071525574\n",
      "====================\n",
      "category        : /Arts & Entertainment/Comics & Animation/Anime & Manga\n",
      "confidence      : 0.6600000262260437\n"
     ]
    }
   ],
   "source": [
    "result = classify(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Games': 0.6800000071525574,\n",
       " '/Arts & Entertainment/Comics & Animation/Anime & Manga': 0.6600000262260437}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Games', 'Anime & Manga']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_found = list(result.keys())\n",
    "\n",
    "tf = []\n",
    "for topic in tags_found:\n",
    "    t = tf.append(topic.rsplit('/',1)[1])\n",
    "    \n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anime & Manga'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.rsplit('/',1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6800000071525574, 0.6399999856948853, 0.5299999713897705]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_conf = []\n",
    "for tag in tags_found:\n",
    "    c = conf.append(result[str(tag)])\n",
    "    \n",
    "tags_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'News': 0.6800000071525574,\n",
       " 'Sensitive Subjects': 0.6399999856948853,\n",
       " 'Law & Government': 0.5299999713897705}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_found = [s.strip('/') for s in tags_found]\n",
    "#dict(zip(tags_found, conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['test'] = tags_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/News'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language\n",
    "\n",
    "def classify(text):\n",
    "    \"\"\"Classify the input text into categories. \"\"\"\n",
    "\n",
    "    language_client = language.LanguageServiceClient()\n",
    "\n",
    "    document = language.types.Document(\n",
    "        content=text,\n",
    "        type=language.enums.Document.Type.PLAIN_TEXT)\n",
    "    response = language_client.classify_text(document)\n",
    "    categories = response.categories\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    for category in categories:\n",
    "        # Turn the categories into a dictionary of the form:\n",
    "        # {category.name: category.confidence}, so that they can\n",
    "        # be treated as a sparse vector.\n",
    "        result[category.name] = category.confidence\n",
    "\n",
    "\n",
    "    tags_found = list(result.keys())\n",
    "    \n",
    "    if len(tags_found) > 5:\n",
    "        tags_found = tags_found[0:5]\n",
    "        \n",
    "    print(tags_found)\n",
    "\n",
    "    tf = []\n",
    "    for topic in tags_found:\n",
    "        t = tf.append(topic.rsplit('/',1)[1])\n",
    "    \n",
    "    print(tf)\n",
    "\n",
    "    tags_conf = []\n",
    "    for tag in tags_found:\n",
    "        c = tags_conf.append(result[str(tag)])\n",
    "\n",
    "    # tags_found = [s.strip('/') for s in tags_found]\n",
    "\n",
    "    return tf, tags_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Games', '/Arts & Entertainment/Comics & Animation/Anime & Manga']\n",
      "['Games', 'Anime & Manga']\n"
     ]
    }
   ],
   "source": [
    "top, conf = classify(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-cbfdaa3d3359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "top.rsplit('/',1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6800000071525574, 0.6600000262260437]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
